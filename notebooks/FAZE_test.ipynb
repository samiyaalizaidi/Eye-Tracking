{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMoM9daSwdOo8RwpW3cFWYe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samiyaalizaidi/Eye-Tracking/blob/main/notebooks/FAZE_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Implementation of **FAZE: Few-Shot Adaptive Gaze Estimation**\n",
        "\n",
        "For more information: [[GitHub](https://github.com/NVlabs/few_shot_gaze.git)] [[Paper](https://openaccess.thecvf.com/content_ICCV_2019/papers/Park_Few-Shot_Adaptive_Gaze_Estimation_ICCV_2019_paper.pdf)]\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Clone the repository"
      ],
      "metadata": {
        "id": "4BVNF5b7OrtJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m49QLvoIOe2v",
        "outputId": "128d9c55-44c5-40d4-ef4e-104b996d8dc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'few_shot_gaze'...\n",
            "remote: Enumerating objects: 259, done.\u001b[K\n",
            "remote: Counting objects: 100% (255/255), done.\u001b[K\n",
            "remote: Compressing objects: 100% (137/137), done.\u001b[K\n",
            "remote: Total 259 (delta 127), reused 234 (delta 114), pack-reused 4\u001b[K\n",
            "Receiving objects: 100% (259/259), 37.79 MiB | 26.71 MiB/s, done.\n",
            "Resolving deltas: 100% (127/127), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/NVlabs/few_shot_gaze.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git submodule update --init --recursive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsftR3VZPIK2",
        "outputId": "bd380ef5-2ad9-47f6-d822-ba5c9757efbb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash grab_prerequisites.bash"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B58kvlGWRWf8",
        "outputId": "cf344bf5-8c3d-434c-c120-bf1f22b58995"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bash: grab_prerequisites.bash: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install the Pre-Requisites"
      ],
      "metadata": {
        "id": "HjWTFCTXPhFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd few_shot_gaze && pip3 install --user --upgrade -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdeaN3cTPkrg",
        "outputId": "342b2ab3-bcaa-4e8b-b33b-34550b523f32"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting apex (from -r requirements.txt (line 1))\n",
            "  Downloading apex-0.9.10dev.tar.gz (36 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (3.9.0)\n",
            "Collecting h5py (from -r requirements.txt (line 2))\n",
            "  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (2.31.6)\n",
            "Collecting imageio (from -r requirements.txt (line 3))\n",
            "  Downloading imageio-2.34.1-py3-none-any.whl (313 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.5/313.5 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.25.2)\n",
            "Collecting numpy (from -r requirements.txt (line 5))\n",
            "  Downloading numpy-2.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv_python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (4.8.0.76)\n",
            "Collecting opencv_python (from -r requirements.txt (line 6))\n",
            "  Downloading opencv_python-4.10.0.82-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (2.3.0+cu121)\n",
            "Collecting torch (from -r requirements.txt (line 7))\n",
            "  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.18.0+cu121)\n",
            "Collecting torchvision (from -r requirements.txt (line 8))\n",
            "  Downloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (4.66.4)\n",
            "Collecting tensorboardX (from -r requirements.txt (line 10))\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cryptacular (from apex->-r requirements.txt (line 1))\n",
            "  Downloading cryptacular-1.6.2.tar.gz (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.8/75.8 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting zope.sqlalchemy (from apex->-r requirements.txt (line 1))\n",
            "  Downloading zope.sqlalchemy-3.1-py3-none-any.whl (23 kB)\n",
            "Collecting velruse>=1.0.3 (from apex->-r requirements.txt (line 1))\n",
            "  Downloading velruse-1.1.1.tar.gz (709 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m709.8/709.8 kB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyramid>1.1.2 (from apex->-r requirements.txt (line 1))\n",
            "  Downloading pyramid-2.0.2-py3-none-any.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.3/247.3 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyramid_mailer (from apex->-r requirements.txt (line 1))\n",
            "  Downloading pyramid_mailer-0.15.1-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from apex->-r requirements.txt (line 1)) (2.31.0)\n",
            "Collecting wtforms (from apex->-r requirements.txt (line 1))\n",
            "  Downloading wtforms-3.1.2-py3-none-any.whl (145 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wtforms-recaptcha (from apex->-r requirements.txt (line 1))\n",
            "  Downloading wtforms_recaptcha-0.3.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio->-r requirements.txt (line 3)) (9.4.0)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy->-r requirements.txt (line 4)) (4.4.2)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy->-r requirements.txt (line 4)) (0.1.10)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy->-r requirements.txt (line 4)) (0.5.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 7)) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 7)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 7)) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 7)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 7)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 7)) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->-r requirements.txt (line 7))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->-r requirements.txt (line 7))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->-r requirements.txt (line 7))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->-r requirements.txt (line 7))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->-r requirements.txt (line 7))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->-r requirements.txt (line 7))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->-r requirements.txt (line 7))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->-r requirements.txt (line 7))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->-r requirements.txt (line 7))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->-r requirements.txt (line 7))\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->-r requirements.txt (line 7))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting triton==2.3.1 (from torch->-r requirements.txt (line 7))\n",
            "  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->-r requirements.txt (line 7))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m72.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX->-r requirements.txt (line 10)) (24.1)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX->-r requirements.txt (line 10)) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy->-r requirements.txt (line 4)) (67.7.2)\n",
            "Collecting hupper>=1.5 (from pyramid>1.1.2->apex->-r requirements.txt (line 1))\n",
            "  Downloading hupper-1.12.1-py3-none-any.whl (22 kB)\n",
            "Collecting plaster (from pyramid>1.1.2->apex->-r requirements.txt (line 1))\n",
            "  Downloading plaster-1.1.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting plaster-pastedeploy (from pyramid>1.1.2->apex->-r requirements.txt (line 1))\n",
            "  Downloading plaster_pastedeploy-1.0.1-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting translationstring>=0.4 (from pyramid>1.1.2->apex->-r requirements.txt (line 1))\n",
            "  Downloading translationstring-1.4-py2.py3-none-any.whl (15 kB)\n",
            "Collecting venusian>=1.0 (from pyramid>1.1.2->apex->-r requirements.txt (line 1))\n",
            "  Downloading venusian-3.1.0-py3-none-any.whl (13 kB)\n",
            "Collecting webob>=1.8.3 (from pyramid>1.1.2->apex->-r requirements.txt (line 1))\n",
            "  Downloading WebOb-1.8.7-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.0/115.0 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting zope.deprecation>=3.5.0 (from pyramid>1.1.2->apex->-r requirements.txt (line 1))\n",
            "  Downloading zope.deprecation-5.0-py3-none-any.whl (10 kB)\n",
            "Collecting zope.interface>=3.8.0 (from pyramid>1.1.2->apex->-r requirements.txt (line 1))\n",
            "  Downloading zope.interface-6.4.post2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.8/247.8 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->apex->-r requirements.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->apex->-r requirements.txt (line 1)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->apex->-r requirements.txt (line 1)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->apex->-r requirements.txt (line 1)) (2024.6.2)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from velruse>=1.0.3->apex->-r requirements.txt (line 1)) (1.3.1)\n",
            "Collecting anykeystore (from velruse>=1.0.3->apex->-r requirements.txt (line 1))\n",
            "  Downloading anykeystore-0.2.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python3-openid (from velruse>=1.0.3->apex->-r requirements.txt (line 1))\n",
            "  Downloading python3_openid-3.2.0-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pbkdf2 (from cryptacular->apex->-r requirements.txt (line 1))\n",
            "  Downloading pbkdf2-1.3.tar.gz (6.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 7)) (2.1.5)\n",
            "Collecting repoze.sendmail>=4.1 (from pyramid_mailer->apex->-r requirements.txt (line 1))\n",
            "  Downloading repoze.sendmail-4.4.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transaction (from pyramid_mailer->apex->-r requirements.txt (line 1))\n",
            "  Downloading transaction-4.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.6/46.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 7)) (1.3.0)\n",
            "Requirement already satisfied: SQLAlchemy!=1.4.0,!=1.4.1,!=1.4.2,!=1.4.3,!=1.4.4,!=1.4.5,!=1.4.6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from zope.sqlalchemy->apex->-r requirements.txt (line 1)) (2.0.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy!=1.4.0,!=1.4.1,!=1.4.2,!=1.4.3,!=1.4.4,!=1.4.5,!=1.4.6,>=1.1->zope.sqlalchemy->apex->-r requirements.txt (line 1)) (3.0.3)\n",
            "Collecting PasteDeploy>=2.0 (from plaster-pastedeploy->pyramid>1.1.2->apex->-r requirements.txt (line 1))\n",
            "  Downloading PasteDeploy-3.1.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from python3-openid->velruse>=1.0.3->apex->-r requirements.txt (line 1)) (0.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib->velruse>=1.0.3->apex->-r requirements.txt (line 1)) (3.2.2)\n",
            "Building wheels for collected packages: apex, velruse, cryptacular, anykeystore, pbkdf2\n",
            "  Building wheel for apex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for apex: filename=apex-0.9.10.dev0-py3-none-any.whl size=46442 sha256=9d5ced292c7996823d19a8329a480ba7198216dc75fdeccbae5336cebcca50dd\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/62/59/9b100fce7ebd989603b3b7a4ca259150da72c9e107fcaa2a30\n",
            "  Building wheel for velruse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for velruse: filename=velruse-1.1.1-py3-none-any.whl size=50909 sha256=ec8edeaeb29905abcaa5f6d29e770ed2e00985a0914b0a3e9e1e0b623240e4a3\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/f9/a4/fc4ea7b935ee9c58b9bc772cabd94f6a8560f35444097d948d\n",
            "  Building wheel for cryptacular (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cryptacular: filename=cryptacular-1.6.2-cp310-cp310-linux_x86_64.whl size=55088 sha256=7521aebcec5bfb53c9665a9f661c2f56b740d8fb256e2b088fa95d96bc406da7\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/6e/09/a7fba517f95b2a6a36bd01b6d4f4679fa7259615a493b64b8f\n",
            "  Building wheel for anykeystore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for anykeystore: filename=anykeystore-0.2-py3-none-any.whl size=16813 sha256=09702804a22e09c02ce560e9a68ece16462448f92106929da3124220454f072c\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/9e/24/35542b7d376b53a6f8426524cc5a3f7998f975037b32d19906\n",
            "  Building wheel for pbkdf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pbkdf2: filename=pbkdf2-1.3-py3-none-any.whl size=5083 sha256=df2b2d6e32caeb1a4832d837276ab717ecad9892dd3a4d068590dfcfad03c5e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/7d/8b/4269ff90fda80497ec59f6ff7d1e1596cb697c1dc8e9bbe320\n",
            "Successfully built apex velruse cryptacular anykeystore pbkdf2\n",
            "Installing collected packages: translationstring, pbkdf2, anykeystore, zope.interface, zope.deprecation, wtforms, webob, venusian, triton, python3-openid, plaster, PasteDeploy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, hupper, cryptacular, wtforms-recaptcha, transaction, tensorboardX, plaster-pastedeploy, opencv_python, nvidia-cusparse-cu12, nvidia-cudnn-cu12, imageio, h5py, zope.sqlalchemy, repoze.sendmail, pyramid, nvidia-cusolver-cu12, velruse, torch, pyramid_mailer, torchvision, apex\n",
            "\u001b[33m  WARNING: The scripts f2py and numpy-config are installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script hupper is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The scripts imageio_download_bin and imageio_remove_bin are installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The script qp is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The scripts pdistreport, prequest, proutes, pserve, pshell, ptweens and pviews are installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The scripts convert-caffe2-to-onnx, convert-onnx-to-caffe2 and torchrun are installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "astropy 5.3.4 requires numpy<2,>=1.21, but you have numpy 2.0.0 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires numpy<2.0a0,>=1.23, but you have numpy 2.0.0 which is incompatible.\n",
            "cupy-cuda12x 12.2.0 requires numpy<1.27,>=1.20, but you have numpy 2.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires numpy<2,>=1, but you have numpy 2.0.0 which is incompatible.\n",
            "numba 0.58.1 requires numpy<1.27,>=1.22, but you have numpy 2.0.0 which is incompatible.\n",
            "rmm-cu12 24.4.0 requires numpy<2.0a0,>=1.23, but you have numpy 2.0.0 which is incompatible.\n",
            "scipy 1.11.4 requires numpy<1.28.0,>=1.21.6, but you have numpy 2.0.0 which is incompatible.\n",
            "tensorflow 2.15.0 requires numpy<2.0.0,>=1.23.5, but you have numpy 2.0.0 which is incompatible.\n",
            "torchaudio 2.3.0+cu121 requires torch==2.3.0, but you have torch 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PasteDeploy-3.1.0 anykeystore-0.2 apex-0.9.10.dev0 cryptacular-1.6.2 h5py-3.11.0 hupper-1.12.1 imageio-2.34.1 numpy-2.0.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 opencv_python-4.10.0.82 pbkdf2-1.3 plaster-1.1.2 plaster-pastedeploy-1.0.1 pyramid-2.0.2 pyramid_mailer-0.15.1 python3-openid-3.2.0 repoze.sendmail-4.4.1 tensorboardX-2.6.2.2 torch-2.3.1 torchvision-0.18.1 transaction-4.0 translationstring-1.4 triton-2.3.1 velruse-1.1.1 venusian-3.1.0 webob-1.8.7 wtforms-3.1.2 wtforms-recaptcha-0.3.2 zope.deprecation-5.0 zope.interface-6.4.post2 zope.sqlalchemy-3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Obtain the weights"
      ],
      "metadata": {
        "id": "Nmezv3jIPtDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd src/\n",
        "! wget -N https://files.ait.ethz.ch/projects/faze/outputs_of_full_train_test_and_plot.zip\n",
        "! unzip -o outputs_of_full_train_test_and_plot.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6vNQkrKPPaW",
        "outputId": "53eb476a-238d-4e00-fb36-1a66447a3914"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: cd: src/: No such file or directory\n",
            "--2024-06-16 13:35:16--  https://files.ait.ethz.ch/projects/faze/outputs_of_full_train_test_and_plot.zip\n",
            "Resolving files.ait.ethz.ch (files.ait.ethz.ch)... 129.132.114.75\n",
            "Connecting to files.ait.ethz.ch (files.ait.ethz.ch)|129.132.114.75|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1250559857 (1.2G) [application/zip]\n",
            "Saving to: ‘outputs_of_full_train_test_and_plot.zip’\n",
            "\n",
            "outputs_of_full_tra 100%[===================>]   1.16G  23.8MB/s    in 55s     \n",
            "\n",
            "2024-06-16 13:36:12 (21.5 MB/s) - ‘outputs_of_full_train_test_and_plot.zip’ saved [1250559857/1250559857]\n",
            "\n",
            "Archive:  outputs_of_full_train_test_and_plot.zip\n",
            "   creating: outputs_of_full_train_test_and_plot/\n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64 MAML GazeCapture (test).pdf  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64 MAML MPIIGaze.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/events.out.tfevents.1577856109.984119  \n",
            "  inflating: outputs_of_full_train_test_and_plot/gc_train_predictions.h5  \n",
            "  inflating: outputs_of_full_train_test_and_plot/gc_val_predictions.h5  \n",
            "  inflating: outputs_of_full_train_test_and_plot/gc_test_predictions.h5  \n",
            "  inflating: outputs_of_full_train_test_and_plot/events.out.tfevents.1577856107.984119  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64 MAML GazeCapture (test).txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64 MAML MPIIGaze.pdf  \n",
            "  inflating: outputs_of_full_train_test_and_plot/mpi_predictions.h5  \n",
            "   creating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/\n",
            "   creating: outputs_of_full_train_test_and_plot/checkpoints/\n",
            "  inflating: outputs_of_full_train_test_and_plot/checkpoints/at_step_0057101.pth.tar  \n",
            "   creating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_06/\n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_06/losses_mpi_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_06/predictions_mpi.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_06/predictions_gc.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_06/meta_learned_parameters.pth.tar  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_06/losses_gc_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_06/events.out.tfevents.1577848508.984119  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_06/losses_gc_valid.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_06/losses_mpi_valid.txt  \n",
            "   creating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_05/\n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_05/losses_mpi_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_05/predictions_mpi.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_05/predictions_gc.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_05/meta_learned_parameters.pth.tar  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_05/losses_gc_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_05/events.out.tfevents.1577848508.984119  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_05/losses_gc_valid.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_05/losses_mpi_valid.txt  \n",
            "   creating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_03/\n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_03/losses_mpi_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_03/predictions_mpi.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_03/events.out.tfevents.1577848507.984119  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_03/predictions_gc.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_03/meta_learned_parameters.pth.tar  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_03/losses_gc_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_03/losses_gc_valid.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_03/losses_mpi_valid.txt  \n",
            "   creating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_64/\n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_64/events.out.tfevents.1577848505.984119  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_64/losses_mpi_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_64/predictions_mpi.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_64/predictions_gc.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_64/meta_learned_parameters.pth.tar  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_64/losses_gc_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_64/losses_gc_valid.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_64/losses_mpi_valid.txt  \n",
            "   creating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_08/\n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_08/losses_mpi_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_08/predictions_mpi.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_08/events.out.tfevents.1577848507.984119  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_08/predictions_gc.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_08/meta_learned_parameters.pth.tar  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_08/losses_gc_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_08/losses_gc_valid.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_08/losses_mpi_valid.txt  \n",
            "   creating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_04/\n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_04/losses_mpi_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_04/predictions_mpi.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_04/predictions_gc.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_04/meta_learned_parameters.pth.tar  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_04/losses_gc_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_04/events.out.tfevents.1577848508.984119  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_04/losses_gc_valid.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_04/losses_mpi_valid.txt  \n",
            "   creating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_01/\n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_01/losses_mpi_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_01/predictions_mpi.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_01/events.out.tfevents.1577848507.984119  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_01/predictions_gc.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_01/meta_learned_parameters.pth.tar  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_01/losses_gc_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_01/losses_gc_valid.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_01/losses_mpi_valid.txt  \n",
            "   creating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_32/\n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_32/losses_mpi_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_32/predictions_mpi.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_32/events.out.tfevents.1577848507.984119  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_32/predictions_gc.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_32/meta_learned_parameters.pth.tar  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_32/losses_gc_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_32/losses_gc_valid.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_32/losses_mpi_valid.txt  \n",
            "   creating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_14/\n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_14/losses_mpi_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_14/predictions_mpi.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_14/predictions_gc.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_14/meta_learned_parameters.pth.tar  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_14/losses_gc_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_14/events.out.tfevents.1577848508.984119  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_14/losses_gc_valid.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_14/losses_mpi_valid.txt  \n",
            "   creating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_10/\n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_10/losses_mpi_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_10/predictions_mpi.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_10/events.out.tfevents.1577848507.984119  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_10/predictions_gc.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_10/meta_learned_parameters.pth.tar  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_10/losses_gc_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_10/losses_gc_valid.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_10/losses_mpi_valid.txt  \n",
            "   creating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_12/\n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_12/losses_mpi_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_12/predictions_mpi.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_12/predictions_gc.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_12/meta_learned_parameters.pth.tar  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_12/losses_gc_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_12/events.out.tfevents.1577848508.984119  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_12/losses_gc_valid.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_12/losses_mpi_valid.txt  \n",
            "   creating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_15/\n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_15/losses_mpi_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_15/predictions_mpi.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_15/events.out.tfevents.1577848507.984119  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_15/predictions_gc.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_15/meta_learned_parameters.pth.tar  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_15/losses_gc_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_15/losses_gc_valid.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_15/losses_mpi_valid.txt  \n",
            "   creating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_09/\n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_09/losses_mpi_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_09/predictions_mpi.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_09/predictions_gc.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_09/meta_learned_parameters.pth.tar  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_09/losses_gc_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_09/events.out.tfevents.1577848508.984119  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_09/losses_gc_valid.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_09/losses_mpi_valid.txt  \n",
            "   creating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_13/\n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_13/losses_mpi_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_13/predictions_mpi.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_13/events.out.tfevents.1577848507.984119  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_13/predictions_gc.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_13/meta_learned_parameters.pth.tar  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_13/losses_gc_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_13/losses_gc_valid.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_13/losses_mpi_valid.txt  \n",
            "   creating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_128/\n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_128/losses_mpi_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_128/predictions_mpi.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_128/predictions_gc.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_128/meta_learned_parameters.pth.tar  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_128/losses_gc_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_128/events.out.tfevents.1577848508.984119  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_128/losses_gc_valid.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_128/losses_mpi_valid.txt  \n",
            "   creating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_16/\n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_16/losses_mpi_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_16/predictions_mpi.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_16/events.out.tfevents.1577848507.984119  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_16/predictions_gc.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_16/meta_learned_parameters.pth.tar  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_16/losses_gc_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_16/losses_gc_valid.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_16/losses_mpi_valid.txt  \n",
            "   creating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_07/\n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_07/losses_mpi_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_07/predictions_mpi.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_07/predictions_gc.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_07/meta_learned_parameters.pth.tar  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_07/losses_gc_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_07/events.out.tfevents.1577848508.984119  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_07/losses_gc_valid.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_07/losses_mpi_valid.txt  \n",
            "   creating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_02/\n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_02/losses_mpi_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_02/predictions_mpi.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_02/predictions_gc.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_02/meta_learned_parameters.pth.tar  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_02/losses_gc_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_02/events.out.tfevents.1577848508.984119  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_02/losses_gc_valid.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_02/losses_mpi_valid.txt  \n",
            "   creating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_256/\n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_256/losses_mpi_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_256/predictions_mpi.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_256/events.out.tfevents.1577848507.984119  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_256/predictions_gc.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_256/meta_learned_parameters.pth.tar  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_256/losses_gc_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_256/losses_gc_valid.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_256/losses_mpi_valid.txt  \n",
            "   creating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_17/\n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_17/losses_mpi_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_17/predictions_mpi.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_17/events.out.tfevents.1577848507.984119  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_17/predictions_gc.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_17/meta_learned_parameters.pth.tar  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_17/losses_gc_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_17/losses_gc_valid.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_17/losses_mpi_valid.txt  \n",
            "   creating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_18/\n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_18/losses_mpi_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_18/predictions_mpi.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_18/events.out.tfevents.1577848507.984119  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_18/predictions_gc.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_18/meta_learned_parameters.pth.tar  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_18/losses_gc_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_18/losses_gc_valid.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_18/losses_mpi_valid.txt  \n",
            "   creating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_11/\n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_11/losses_mpi_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_11/predictions_mpi.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_11/events.out.tfevents.1577848507.984119  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_11/predictions_gc.pkl  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_11/meta_learned_parameters.pth.tar  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_11/losses_gc_train.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_11/losses_gc_valid.txt  \n",
            "  inflating: outputs_of_full_train_test_and_plot/Zg_OLR1e-03_IN5_ILR1e-05_Net64/MAML_11/losses_mpi_valid.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running the all-in-one bash\n"
      ],
      "metadata": {
        "id": "k9VX28h1P6P7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! cd src/\n",
        "! bash full_train_test_and_plot.bash"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cY8m2GRyP-G0",
        "outputId": "45773cde-c209-4cfe-dc45-7235bde65a19"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: cd: src/: No such file or directory\n",
            "bash: full_train_test_and_plot.bash: No such file or directory\n"
          ]
        }
      ]
    }
  ]
}